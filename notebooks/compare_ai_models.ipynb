{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_ai_models.ipynb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Set up logging for chain-of-thought outputs\n",
    "logging.basicConfig(\n",
    "    filename='../logs/reasoning.log',  # Adjust path if running from notebook root\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.model_interface import query_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: {'openai': {'models': ['gpt-4o', 'gpt-3.5-turbo']}, 'meta': {'models': ['meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Meta-Llama-3-8B-Instruct']}, 'gemini': {'models': []}, 'mistral': {'models': []}, 'claude': {'models': []}, 'deepseek': {'models': []}}\n"
     ]
    }
   ],
   "source": [
    "config_path = '../config/models_config.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    model_catalog = yaml.safe_load(file)\n",
    "print(\"Available models:\", model_catalog)\n",
    "\n",
    "# Choose models from the config:\n",
    "model_1 = model_catalog[\"openai\"][\"models\"][0]  # e.g., \"gpt-4o\"\n",
    "provider_1 = \"openai\"\n",
    "model_2 = model_catalog[\"meta\"][\"models\"][0]      # e.g., \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "provider_2 = \"meta\"\n",
    "evaluation_provider_ = \"openai\"\n",
    "evaluation_model_ = model_catalog[\"openai\"][\"models\"][0]  # \"gpt-4o\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain why Paris is called the city of lights.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1, out2, evaluation = compare_models(\n",
    "    prompt,\n",
    "    model1=model_1, provider1=provider_1,\n",
    "    model2=model_2, provider2=provider_2,\n",
    "    evaluation_provider=evaluation_provider_, evaluation_model=evaluation_model_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from gpt-4o :\n",
      " Paris is often referred to as \"The City of Lights\" for a couple of reasons:\n",
      "\n",
      "1. **Enlightenment Era**: Paris was a leading center of education and ideas during the Age of Enlightenment in the 18th century. This era was characterized by an emphasis on reason, science, and intellectual exchange, with Paris at the forefront. Philosophers, writers, and artists flocked to the city, contributing to its reputation as a hub of enlightenment and knowledge.\n",
      "\n",
      "2. **Pioneering Street Lighting**: Another reason for the nickname stems from its early adoption of street lighting. In the 17th century, under the reign of King Louis XIV, efforts were made to increase safety in the city's streets by introducing lanterns. By the 19th century, Paris became one of the first cities to implement gas street lighting, further enhancing its reputation for being well-lit and safe at night. This innovative use of lighting not only improved security but also added to the city's dazzling and vibrant ambiance.\n",
      "\n",
      "Together, these historical and cultural factors contribute to Paris's enduring nickname as \"The City of Lights.\"\n",
      "\n",
      "Response from meta-llama/Llama-2-7b-chat-hf :\n",
      " Error: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf\n",
      "\n",
      "Evaluation by gpt-4o :\n",
      " In evaluating the two responses to the prompt asking why Paris is called \"The City of Lights,\" it's clear that the response from OpenAI's GPT-4o is the most suitable and informative. Here’s why:\n",
      "\n",
      "1. **Content and Completeness**: The GPT-4o response provides a well-rounded explanation that covers both historical and cultural aspects. It addresses the Enlightenment Era’s impact on Paris’s reputation as a center of intellectual and cultural advancement. Additionally, it explains the technological aspect of street lighting that contributed to the nickname. This dual approach enhances understanding by providing multiple reasons for the moniker.\n",
      "\n",
      "2. **Accuracy and Depth**: The explanation appears to be accurate and reflects a deep understanding of the historical context. By referring to the Age of Enlightenment and the pioneering use of street lighting, the response pinpoints key periods in history that are intrinsically linked to Paris’s identity.\n",
      "\n",
      "3. **Clarity and Organization**: The response is well-structured and divided into clear points, making it easy to follow and understand. The use of numbered sections helps in organizing the information effectively.\n",
      "\n",
      "4. **Relevance**: The response directly addresses the prompt with relevant information, remaining focused on explaining the reasons behind the nickname.\n",
      "\n",
      "On the other hand, the response from Meta (meta-llama/Llama-2-7b-chat-hf) unfortunately does not exist due to a technical error, and hence cannot be evaluated or provide any useful information. In an evaluation context, a non-response due to error cannot be considered better than a complete and informative response.\n",
      "\n",
      "Therefore, the response from GPT-4o is clearly the stronger and better response, as it successfully delivers a comprehensive, well-explained answer to the prompt.\n"
     ]
    }
   ],
   "source": [
    "print(\"Response from\", model_1, \":\\n\", out1)\n",
    "print(\"\\nResponse from\", model_2, \":\\n\", out2)\n",
    "print(\"\\nEvaluation by\", evaluation_model_, \":\\n\", evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compare-gen-ai-outputs-oJZNtxB8-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
